\title{CS 613 - Machine Learning}
\author{
        Assignment 2 - Linear Regression\\
        Fall 2016
}
\date{}
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{amsmath}


\begin{document}
\maketitle


\section*{Introduction}
In this assignment you will perform linear regression on a dataset and using cross-validation to analyze your results.  In addition to computing and applying the close-form solution, you will also implement from scratch a gradient descent algorithm for linear regression.\\

\noindent
You may \textbf{not} use any function from the Matlab ML library in your code.  And as always your code should work on any dataset that has the same general form as the provided one.

\section*{Grading}
\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|}
\hline
Part 1 (theory) & 10pts\\
Part 2 (closed-form LR) & 20pts\\
Part 3 (s-folds LR) & 10pts\\
Part 4 (Local LR) & 20pts\\
Part 5 (GD LR) & 30pts\\
Report & 10pts\\
\hline
\textbf{TOTAL} & 100 \\
\hline
Code doesn't generalize & -10pts\\
\hline
\end{tabular}
\caption{Grading Rubric}
\end{center}
\end{table}

\newpage
\section*{Datasets}
\paragraph{Fish Length Dataset  (x06Simple.csv)}
This dataset consists of 44 rows of data each of the form:
\begin{enumerate}
\item Index
\item Age (days)
\item Temperature of Water (degrees Celsius)
\item Length of Fish
\end{enumerate}
The first row of the data contains header information.\\

\noindent
Data obtained from:  http://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html

\newpage
\section{Theory}
\begin{enumerate}
\item Consider the following data:\\
\begin{center}
$
 \begin{bmatrix}
	-2 & 1\\
	-5 & -4\\	
	-3 & 1\\
	0 & 3\\
	-8 & 11\\
	-2 & 5\\
	1 & 0\\
	5 & -1\\
	-1 & -3\\
	6 & 1\\
\end{bmatrix}
$
\end{center}
	\begin{enumerate}
	\item Compute the coefficients for the linear regression using global least squares estimate (LSE) where the second value is the dependent variable (the value to be predicted).  Show your work and remember to add a bias feature and to standardize the features (10pts).\\
	\end{enumerate}
\end{enumerate}


\newpage
\section{Closed Form Linear Regression}\label{linreg}
Download the dataset \emph{x06Simple.csv} from Blackboard.  This dataset has header information in its first row and then all subsequent rows are in the format:
\begin{center}
$ROWId, x_{i,1}, x_{i,2}, y_i$
\end{center}
Your code should work on any CSV data set that has the first column be header information, the first column be some integer index, then $D$ columns of real-valued features, and then ending with a target value.\\

\noindent
\paragraph{Write a script that:}
\begin{enumerate}
  \item Reads in the data, ignoring the first row (header) and first column (index).
  \item Randomizes the data
  \item Selects the first 2/3 (round up) of the data for training and the remaining for testing
  \item Standardizes the data (except for the last column of course) using the training data
  \item Computes the closed-form solution of linear regression
  \item Applies the solution to the testing samples
  \item Computes the \emph{root mean squared error} (RMSE): $\sqrt{\frac{1}{N}\sum_{i=1}^N (y_i-\hat{y_i})^2}$. where $\hat{y_i}$ is the predicted value for obseration $x_i$.
\end{enumerate}


\paragraph{Implementation Details}
\begin{enumerate}
\item Seed the random number generate with zero prior to randomizing the data
\item Don't forget to add in the offset feature!
\end{enumerate}


\paragraph{In your report you will need:}
\begin{enumerate}
\item The final model in the form $y=w_0+w_1x_{:,1} + ...$
\item The root mean squared error.
\end{enumerate}



\newpage
\section{S-Folds Cross-Validation}\label{linreg}
Cross-Validation is a technique used to get reliable evaluation results when we don't have that much data (and it is therefore difficult to train and/or test a model reliably).\\

\noindent
In this section you will divide your data up into 5 parts and train/test 5 different models using the 5-Folds Cross-Validation.  We can then look at the root mean squared error using all the errors.\\

\paragraph{Write a script that:}
\begin{enumerate}
  \item Reads in the data, ignoring the first row (header) and first column (index).
  \item Randomizes the data
  \item Creates $S$ folds (for our purposes $S=5$, but make your code generalizable, that is it should work for any legal value of $S$)
  \item For $i=1$ to $S$
  \begin{enumerate}
  	\item Select fold $i$ as your testing data and the remaining $(S-1)$ folds as your training data
	\item Standardizes the data (except for the last column of course) based on the training data
	\item Train a closed-form linear regression model
  	\item Compute the squared error for each sample in the current testing fold
  \end{enumerate}
  \item Compute the RMSE using all the errors.
\end{enumerate}


\paragraph{Implementation Details}
\begin{enumerate}
\item Seed the random number generate with zero prior to randomizing the data
\item Don't forget to add in the offset feature!
\end{enumerate}


\paragraph{In your report you will need:}
\begin{enumerate}
\item The root mean squared error.
\end{enumerate}


\newpage
\section{Locally-Weighted Linear Regression}
\noindent
Next we'll do locally-weighted closed-form linear regression.\\

\paragraph{Write a script to:}
\begin{enumerate}
  \item Read in the data, ignoring the first row (header) and first column (index).
  \item Randomize the data
  \item Select the first 2/3 (round up) of the data for training and the remaining for testing
  \item Standardize the data (except for the last column of course) using the training data
  \item Then for each \emph{testing sample}
  	\begin{enumerate}
  	\item Compute the necessary distance matrices relative to the training data in order to compute a local model.
  	\item Evaluate the testing sample using the local model.
  	\item Compute the squared error of the testing sample.
  	\end{enumerate}
  \item Compute the \emph{root mean squared error} (RMSE): $\sqrt{\frac{1}{N}\sum_{i=1}^N (y_i-\hat{y_i})^2}$. where $\hat{y_i}$ is the predicted value for obseration $x_i$ using the squared errors of the testing samples.
\end{enumerate}


\paragraph{Implementation Details}
\begin{enumerate}
\item Seed the random number generate with zero prior to randomizing the data
\item Don't forget to add in the offset feature!
\item Use the L1 distance when computing the distance matrices.
\item Let $k=1$ in the similarity function $\beta(a,b)= e^{-d(a,b)/k^2}$.
\item Use \emph{all} training instances when computing the local model.
\end{enumerate}


\paragraph{In your report you will need:}
\begin{enumerate}
\item The root mean squared error.
\end{enumerate}


\newpage
\section{Gradient Descent}
As discussed in class Gradient Descent (Ascent) is a general algorithm that allows us to converge on local minima (maxima) when a closed-form solution is not available or is not feasible to compute.\\

\noindent
In this section you are going to implement a gradient descent algorithm to find the parameters for linear regression on the same data used for the previous sections.  You may \textbf{NOT} use any function for a ML library to do this for you.

\paragraph{Implementation Details}
\begin{enumerate}
\item Seed the random number generator prior to your algorithm.
\item Don't forget to add in the offset feature!
\item Initialize the parameters of $W$ using random values in the range [-1, 1]
\item Do \textbf{batch} gradient descent
\item Terminate when absolute value of the percent change in the RMSE on the \textbf{training} data is less than the Matlab defined \emph{eps} or after $1,000,000$ iterations have passed (whichever occurs first).
\item Use a learning rate $\alpha=0.01$.
\item Make sure that you code can work for an arbitrary number of observations and an arbitrary number of features.
\end{enumerate}


\paragraph{Write a script that:}
\begin{enumerate}
  \item Reads in the data, ignoring the first row (header) and first column (index).
  \item Randomizes the data
  \item Selects the first 2/3 (round up) of the data for training and the remaining for testing
  \item Standardizes the data (except for the last column of course) base on the training data
  \item While the termination criteria (mentioned above in the implementation details) hasn't been met
  \begin{enumerate}
  	\item Compute the RMSE of the \emph{training} data
  	\item While we can't let the testing set affect our training process, also compute the RMSE of the testing error at each iteration of the algorithm (it'll be interesting to see).
  	\item Update each parameter using \emph{batch} gradient descent
  \end{enumerate}
  \item Compute the RMSE of the testing data.
\end{enumerate}



\paragraph{What you will need for your report}
\begin{enumerate}
\item Final model
\item A graph of the RMSE if the \emph{training} and \emph{testing} sets as a function of the iteration
\item The final RMSE \emph{testing} error.
\end{enumerate}

Your graph should look similar to Figure \ref{GD}.
\begin{figure}[H]
\begin{center}
\includegraphics{GD_RMSE_Training.png}
\caption{Gradient Descent Progress}
\label{GD}
\end{center}
\end{figure}


\newpage
\section*{Submission}
For your submission, upload to Blackboard a single zip file containing:

\begin{enumerate}
\item PDF Writeup
\item Source Code
\item readme.txt file
\end{enumerate}

\noindent
The readme.txt file should contain information on how to run your code to reproduce results for each part of the assignment.\\

\noindent
The PDF document should contain the following:

\begin{enumerate}
\item Part 1:
	\begin{enumerate}
	\item Your solutions to the theory question
	\end{enumerate}
\item Part 2:
	\begin{enumerate}
	\item Final Model
	\item RMSE
	\end{enumerate}
\item Part 3:
	\begin{enumerate}
	\item RMSE
	\end{enumerate}
\item Part 4:
	\begin{enumerate}
	\item RMSE
	\end{enumerate}	
\item Part 5:
	\begin{enumerate}
	\item Final Model
	\item RMSE
	\item Plot of RMSE for Training and Testing Data vs Gradient Descent iteration number
	\end{enumerate}
\end{enumerate}
\end{document}

